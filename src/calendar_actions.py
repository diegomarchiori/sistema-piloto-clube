import logging
import uuid
import pytz
from datetime import datetime, date, timedelta, time, timezone
from typing import Optional, List, Dict, Any, Tuple
from dateutil import parser
import json

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from google.oauth2.credentials import Credentials
from fastapi import HTTPException

from .models import (
    GoogleCalendarEvent,
    EventsResponse,
    EventCreateRequest,
    EventDateTime,
    EventAttendee,
    EventUpdateRequest,
    CalendarListResponse,
    CalendarListEntry,
    ActionResponse
)

# Define a classe placeholder ANTES do bloco 'try' para garantir que ela sempre exista.
class ProjectedEventOccurrence:
    """Classe placeholder para o tipo ProjectedEventOccurrence."""
    pass

try:
    from .analysis import project_recurring_events, ProjectedEventOccurrence, analyze_busyness
    logging.info("Módulo 'analysis' importado com sucesso.")
except ImportError:
    logging.warning("Módulo '.analysis' não encontrado. Usando funções dummy.")
    def project_recurring_events(*args, **kwargs): return []
    def analyze_busyness(*args, **kwargs): return None

logger = logging.getLogger(__name__)

def _get_calendar_service(credentials: Credentials):
    """Constrói o objeto de serviço do Google Calendar a partir das credenciais fornecidas."""
    try:
        # As 'credentials' que recebemos já estão configuradas para personificação pelo auth.py
        service = build('calendar', 'v3', credentials=credentials)
        return service
    except Exception as e:
        logger.error(f"Falha ao construir o serviço do Google Calendar: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Falha ao construir o serviço do Google Calendar: {e}")
    
_calendar_names_cache = {}
def _get_calendar_name(service, calendar_id: str) -> str:
    if calendar_id in _calendar_names_cache:
        return _calendar_names_cache[calendar_id]
    try:
        calendar = service.calendars().get(calendarId=calendar_id).execute()
        summary = calendar.get('summary', calendar_id)
        _calendar_names_cache[calendar_id] = summary
        return summary
    except HttpError:
        return calendar_id
    
# ==============================================================================
# FUNÇÕES COM A NOVA LÓGICA DE BLOQUEIO COMPARTILHADO E DE ENVELOPE
# ==============================================================================

def _get_overlapping_blocks(service, calendar_id: str, start_time: datetime, end_time: datetime) -> List[Dict]:
    try:
        events_result = service.events().list(
            calendarId=calendar_id,
            timeMin=start_time.isoformat(),
            timeMax=end_time.isoformat(),
            sharedExtendedProperty="autoGeneratedBy=courtBookingSystemMCP",
            singleEvents=True
        ).execute()
        return events_result.get('items', [])
    except HttpError:
        return []

def _update_or_create_blocking_events(service, primary_event: Dict, user_info: Dict, settings: dict) -> int:
    # Pega os mapas do objeto de configurações
    quadras_map = settings.get('quadras', {})
    dependency_rules = settings.get('court_dependency_rules', {})

    # Cria um mapa reverso para encontrar o nome simples a partir do ID
    id_to_name_map = {v: k for k, v in quadras_map.items()}

    source_calendar_id = primary_event.get('organizer', {}).get('email')
    source_simple_name = id_to_name_map.get(source_calendar_id)

    if not source_simple_name or source_simple_name not in dependency_rules:
        return 0

    # Pega os nomes simples das quadras dependentes
    dependent_simple_names = dependency_rules.get(source_simple_name, [])
    # Traduz os nomes simples para os IDs reais
    dependent_calendar_ids = [quadras_map.get(name) for name in dependent_simple_names if name in quadras_map]

    main_calendar_name = _get_calendar_name(service, source_calendar_id)
    new_start_dt = parser.isoparse(primary_event['start']['dateTime'])
    new_end_dt = parser.isoparse(primary_event['end']['dateTime'])

    for dep_cal_id in dependent_calendar_ids:
        # O resto da lógica de envelope continua a mesma
        try:
            overlapping_blocks = _get_overlapping_blocks(service, dep_cal_id, new_start_dt, new_end_dt)
            final_start, final_end = new_start_dt, new_end_dt
            all_source_ids = {primary_event['id']}
            for block in overlapping_blocks:
                final_start = min(final_start, parser.isoparse(block['start']['dateTime']))
                final_end = max(final_end, parser.isoparse(block['end']['dateTime']))
                source_ids_str = block.get('extendedProperties', {}).get('private', {}).get('sourceEventIds', '')
                if source_ids_str:
                    all_source_ids.update(source_ids_str.split(','))
                service.events().delete(calendarId=dep_cal_id, eventId=block['id']).execute()
            source_event_summary = primary_event.get('summary', 'Evento Principal')
            new_block_body = {
                'summary': f"Bloqueado - Reserva '{source_event_summary}' ({main_calendar_name})",
                'description': "Este horário está bloqueado por um ou mais agendamentos.",
                'start': {'dateTime': final_start.isoformat(), 'timeZone': 'UTC'},
                'end': {'dateTime': final_end.isoformat(), 'timeZone': 'UTC'},
                'transparency': 'opaque',
                'extendedProperties': {
                    'shared': {'autoGeneratedBy': 'courtBookingSystemMCP'},
                    'private': {'sourceEventIds': ','.join(sorted(list(all_source_ids)))}
                }
            }
            service.events().insert(calendarId=dep_cal_id, body=new_block_body).execute()
            logger.info(f"Bloco consolidado criado/atualizado em {dep_cal_id}.")
        except Exception as e:
            logger.error(f"ERRO ao criar/atualizar bloco em {dep_cal_id}: {e}")

    return len(dependent_calendar_ids)


def _handle_block_updates_on_delete(service, deleted_event: Dict, settings: dict):
    quadras_map = settings.get('quadras', {})
    dependency_rules = settings.get('court_dependency_rules', {})
    id_to_name_map = {v: k for k, v in quadras_map.items()}

    source_calendar_id = deleted_event.get('organizer', {}).get('email')
    source_simple_name = id_to_name_map.get(source_calendar_id)

    if not source_simple_name or source_simple_name not in dependency_rules:
        return

    dependent_simple_names = dependency_rules.get(source_simple_name, [])
    dependent_calendar_ids = [quadras_map.get(name) for name in dependent_simple_names if name in quadras_map]

    deleted_event_id = deleted_event['id']
    start_dt = parser.isoparse(deleted_event['start']['dateTime'])
    end_dt = parser.isoparse(deleted_event['end']['dateTime'])

    for dep_cal_id in dependent_calendar_ids:
        # O resto da lógica de busca e atualização de blocos continua a mesma
        try:
            search_start = start_dt - timedelta(hours=12)
            search_end = end_dt + timedelta(hours=12)
            blocks_in_range = _get_overlapping_blocks(service, dep_cal_id, search_start, search_end)
            for block in blocks_in_range:
                source_ids_str = block.get('extendedProperties', {}).get('private', {}).get('sourceEventIds', '')
                source_ids = set(source_ids_str.split(',')) if source_ids_str else set()
                if deleted_event_id in source_ids:
                    source_ids.remove(deleted_event_id)
                    if not source_ids:
                        logger.info(f"Último dono removido. Deletando bloco {block['id']} em {dep_cal_id}.")
                        service.events().delete(calendarId=dep_cal_id, eventId=block['id']).execute()
                    else:
                        logger.info(f"Removendo referência de {block['id']} em {dep_cal_id}. Bloco mantido.")
                        patch_body = {'extendedProperties': {'private': {'sourceEventIds': ','.join(sorted(list(source_ids)))}}}
                        service.events().patch(calendarId=dep_cal_id, eventId=block['id'], body=patch_body).execute()
        except Exception as e:
            logger.error(f"Erro ao processar atualização de bloqueio em {dep_cal_id} após exclusão: {e}")

def create_event(
    credentials: Credentials, 
    event_data: EventCreateRequest, 
    calendar_id: str, 
    user_info: Dict[str, Any], 
    settings: dict, 
    send_notifications: bool = True
) -> Dict[str, Any]:
    
    service = _get_calendar_service(credentials)
    MAX_RECURRENCES = 30
    potential_slots = []
    
    # Gera um ID único para toda a série, se for um evento recorrente
    series_id = str(uuid.uuid4()) if event_data.frequency and event_data.frequency != 'none' else None

    # Lógica de cálculo de datas (mantida da versão anterior, que está correta)
    if event_data.frequency and event_data.frequency != 'none':
        start_dt_base = event_data.start.date_time.astimezone(pytz.timezone("America/Sao_Paulo"))
        end_dt_base = event_data.end.date_time.astimezone(pytz.timezone("America/Sao_Paulo"))
        duration = end_dt_base - start_dt_base
        end_date_limit = datetime.strptime(event_data.recurrence_end_date, '%Y-%m-%d').date()
        isoweekday_map = {'MO': 1, 'TU': 2, 'WE': 3, 'TH': 4, 'FR': 5, 'SA': 6, 'SU': 7}
        selected_weekdays = {isoweekday_map.get(day) for day in event_data.recurrence_days or []}
        current_date_iterator = start_dt_base.date()
        while current_date_iterator <= end_date_limit:
            if len(potential_slots) >= MAX_RECURRENCES: break
            if (event_data.frequency == 'daily') or (event_data.frequency == 'weekly' and current_date_iterator.isoweekday() in selected_weekdays):
                new_start_dt = datetime.combine(current_date_iterator, start_dt_base.time(), tzinfo=start_dt_base.tzinfo)
                potential_slots.append({'start': new_start_dt, 'end': new_start_dt + duration})
            current_date_iterator += timedelta(days=1)
    else:
        potential_slots.append({'start': event_data.start.date_time, 'end': event_data.end.date_time})
    
    created_events_count = 0
    skipped_events = []

    for slot in potential_slots:
        start_time = slot['start']
        end_time = slot['end']
        try:
            freebusy_query = {"timeMin": start_time.isoformat(), "timeMax": end_time.isoformat(), "items": [{"id": calendar_id}]}
            result = service.freebusy().query(body=freebusy_query).execute()
            
            if result.get('calendars', {}).get(calendar_id, {}).get('busy'):
                # ... (lógica de conflito mantida) ...
                conflicting_event_info = "Evento existente"
                try:
                    events = service.events().list(calendarId=calendar_id, timeMin=start_time.isoformat(), timeMax=end_time.isoformat(), maxResults=1).execute().get('items', [])
                    if events: conflicting_event_info = events[0].get('summary', 'Evento sem título')
                except Exception: pass
                skipped_events.append({"start": start_time.isoformat(), "end": end_time.isoformat(), "reason": conflicting_event_info})
            else:
                extended_properties = {
                    'private': {
                        'requesterEmail': user_info.get('email'), 
                        'requesterName': user_info.get('name')
                    }
                }
                # --- 2. ADICIONA A ETIQUETA 'seriesId' SE FOR RECORRENTE ---
                if series_id:
                    extended_properties['private']['seriesId'] = series_id

                impersonation_user = settings.get('impersonation_user_email')

                event_body = {
                    'summary': event_data.summary,
                    'description': f"{event_data.description or ''}\n\n---\nSolicitado por: {user_info.get('name')} ({user_info.get('email')})",
                    'start': {'dateTime': start_time.isoformat()},
                    'end': {'dateTime': end_time.isoformat()},
                    'extendedProperties': extended_properties,
                }
                
                created_event = service.events().insert(calendarId=calendar_id, body=event_body, sendNotifications=send_notifications).execute()
                _update_or_create_blocking_events(service, created_event, user_info, settings)
                created_events_count += 1
        except Exception as e:
            # ... (lógica de erro mantida) ...
            skipped_events.append({"start": start_time.isoformat(), "end": end_time.isoformat(), "reason": f"Erro interno no servidor: {e}"})

    message = f"{created_events_count} agendamento(s) criados com sucesso."
    if skipped_events:
        message += f" {len(skipped_events)} horários foram pulados por conflito ou erro."

    return {
        "message": message,
        "event": None,
        "created_count": created_events_count,
        "skipped_count": len(skipped_events),
        "skipped_events": skipped_events
    }



def _find_source_calendar(event_id, service):
    # This is a placeholder for a more robust mechanism to find the source calendar if needed.
    # For now, we assume this isn't strictly necessary if the calling function has the calendar_id.
    return None

def delete_event(credentials: Credentials, event_id: str, calendar_id: str, settings: dict, send_notifications: bool = True) -> ActionResponse:
    service = _get_calendar_service(credentials)
    try:
        event_to_delete = service.events().get(calendarId=calendar_id, eventId=event_id).execute()
    except HttpError:
        raise HTTPException(status_code=404, detail="Evento a ser deletado não encontrado.")

    _handle_block_updates_on_delete(service, event_to_delete, settings)

    service.events().delete(calendarId=calendar_id, eventId=event_id, sendNotifications=send_notifications).execute()
    logger.info(f"Evento principal '{event_id}' deletado com sucesso.")
    return ActionResponse(message="Agendamento removido e bloqueios atualizados com sucesso.")

# Em src/calendar_actions.py

def update_event(credentials: Credentials, event_id: str, update_data: EventUpdateRequest, calendar_id: str, user_info: Dict[str, Any], settings: dict, send_notifications: bool = True) -> ActionResponse:
    service = _get_calendar_service(credentials)
    
    try:
        original_event = service.events().get(calendarId=calendar_id, eventId=event_id).execute()
    except HttpError:
         raise HTTPException(status_code=404, detail="Evento a ser atualizado não encontrado.")

    # --- INÍCIO DA OTIMIZAÇÃO E CORREÇÃO ---
    start_time = None
    end_time = None

    if update_data.start and update_data.start.date_time:
        start_time = update_data.start.date_time
    if update_data.end and update_data.end.date_time:
        end_time = update_data.end.date_time
        
    if start_time and end_time:
        if start_time < datetime.now(timezone.utc):
            raise HTTPException(status_code=400, detail="Não é possível reagendar eventos para uma data no passado.")  

        if end_time <= start_time:
            raise HTTPException(status_code=400, detail="A data/hora de fim deve ser posterior à de início.")
        
        # OTIMIZAÇÃO: Usando events.list mas com checagem para evitar auto-conflito.
        # freebusy.query não informa o ID do evento, tornando-o inadequado para updates.
        try:
            conflicting_events = service.events().list(
                calendarId=calendar_id,
                timeMin=start_time.isoformat(),
                timeMax=end_time.isoformat(),
                singleEvents=True
            ).execute().get('items', [])

            # Filtra o próprio evento que está sendo atualizado da lista de conflitos.
            other_conflicts = [ev for ev in conflicting_events if ev.get('id') != event_id]

            if other_conflicts:
                raise HTTPException(status_code=409, detail="O novo horário para o reagendamento está em conflito com outro evento existente.")
        except HttpError as e:
            logger.error(f"Erro de API ao verificar conflitos para atualização: {e}")
            raise HTTPException(status_code=500, detail="Erro ao verificar a disponibilidade para reagendamento.")

    # 2. Lógica de atualização dos bloqueios (removendo os antigos)
    _handle_block_updates_on_delete(service, original_event, settings)

    # 3. Preparação do corpo da atualização
    update_body = {}
    if update_data.summary is not None:
        update_body['summary'] = update_data.summary

    if start_time:
        update_body['start'] = {'dateTime': start_time.isoformat()}
    if end_time:
        update_body['end'] = {'dateTime': end_time.isoformat()}
    
    if not update_body:
        raise HTTPException(status_code=400, detail="Nenhum dado válido para atualização foi fornecido.")
    
    base_description = update_data.description if update_data.description is not None else original_event.get('description', '').split('\n\n---')[0]
    update_body['description'] = f"{base_description}\n\n---\nSolicitado por: {user_info.get('name')} ({user_info.get('email')})"
    # --- FIM DA OTIMIZAÇÃO E CORREÇÃO ---

    # Aplica a atualização no evento principal
    updated_event = service.events().patch(calendarId=calendar_id, eventId=event_id, body=update_body, sendNotifications=send_notifications).execute()

    # Cria/atualiza os bloqueios para o novo horário
    successful_blocks = _update_or_create_blocking_events(service, updated_event, user_info, settings)
    
    summary_name = updated_event.get('summary', 'Sem Título')
    success_message = f"Agendamento '{summary_name}' atualizado com sucesso!"
    if successful_blocks > 0:
        success_message += f" {successful_blocks} agenda(s) dependente(s) foram bloqueada(s)/atualizada(s)."
    
    parsed_event = GoogleCalendarEvent(**updated_event)
    return ActionResponse(message=success_message, event=parsed_event)

def find_events(
    credentials: Credentials,
    calendar_id: str = 'primary',
    time_min: Optional[str] = None, # Alterado para aceitar string
    time_max: Optional[str] = None, # Alterado para aceitar string
    page_token: Optional[str] = None,
    max_results: int = 25,
    single_events: bool = True,
    order_by: str = 'startTime'
) -> Optional[EventsResponse]:
    service = _get_calendar_service(credentials)
    if not service:
        return None
    
    # Monta os argumentos para a chamada da API
    list_kwargs = {
        'calendarId': calendar_id,
        'timeMin': time_min,
        'timeMax': time_max,
        'pageToken': page_token,
        'maxResults': max_results,
        'singleEvents': single_events,
        'orderBy': order_by,
        'showDeleted': False
    }
    
    # Remove chaves com valor None para não enviar parâmetros vazios para a API
    list_kwargs = {k: v for k, v in list_kwargs.items() if v is not None}
    
    logger.info(f"Fetching events from calendar '{calendar_id}' with parameters: {list_kwargs}")
    
    try:
        events_result = service.events().list(**list_kwargs).execute()
        logger.info(f"Found {len(events_result.get('items', []))} events.")
        return EventsResponse(**events_result)
    except HttpError as error:
        logger.error(f"Google API Error: {error}")
        raise error

# Em src/calendar_actions.py, adicione esta nova função

def get_availability(
    credentials: Credentials,
    calendar_id: str,
    time_min: datetime,
    time_max: datetime
) -> List[Dict[str, datetime]]:
    """
    Usa a API freebusy.query para obter uma lista de horários ocupados para um calendário.

    Retorna:
        Uma lista de dicionários, onde cada um representa um intervalo 'busy'.
        Ex: [{'start': datetime_obj, 'end': datetime_obj}]
    """
    service = _get_calendar_service(credentials)
    logger.info(f"Verificando disponibilidade para o calendário '{calendar_id}' entre {time_min} e {time_max}")
    
    try:
        freebusy_query = {
            "timeMin": time_min.isoformat(),
            "timeMax": time_max.isoformat(),
            "items": [{"id": calendar_id}]
        }
        result = service.freebusy().query(body=freebusy_query).execute()
        
        calendar_data = result.get('calendars', {}).get(calendar_id, {})
        if calendar_data.get('errors'):
            error_details = calendar_data['errors'][0].get('reason', 'desconhecido')
            logger.error(f"API do Google retornou um erro ao buscar disponibilidade: {error_details}")
            # Lançamos uma exceção que o server.py pode capturar
            raise HTTPException(status_code=404, detail=f"Não foi possível obter informações para a quadra selecionada (motivo: {error_details}).")

        busy_intervals = calendar_data.get('busy', [])
        
        # Converte as strings de data/hora da resposta em objetos datetime
        parsed_intervals = [
            {
                "start": parser.isoparse(interval['start']),
                "end": parser.isoparse(interval['end'])
            }
            for interval in busy_intervals
        ]
        
        logger.info(f"Encontrados {len(parsed_intervals)} horários ocupados.")
        return parsed_intervals

    except HttpError as e:
        logger.error(f"Erro na chamada da API freebusy.query: {e}")
        raise HTTPException(status_code=500, detail="Erro interno ao consultar a API do Google Calendar.")

def quick_add_event(
    credentials: Credentials, text: str, calendar_id: str = 'primary', send_notifications: bool = False
) -> Optional[GoogleCalendarEvent]:
    service = _get_calendar_service(credentials)
    if not service: return None
    try:
        created_event = service.events().quickAdd(calendarId=calendar_id, text=text, sendNotifications=send_notifications).execute()
        return GoogleCalendarEvent(**created_event)
    except HttpError as error:
        raise error
    except Exception as e:
        raise e

def add_attendee(
    credentials: Credentials, event_id: str, attendee_emails: List[str], calendar_id: str = 'primary', send_notifications: bool = True
) -> Optional[GoogleCalendarEvent]:
    service = _get_calendar_service(credentials)
    if not service: return None
    try:
        event = service.events().get(calendarId=calendar_id, eventId=event_id).execute()
    except HttpError as error:
        raise error
        
    current_attendees = event.get('attendees', [])
    current_emails = {attendee.get('email') for attendee in current_attendees if attendee.get('email')}
    new_attendees_to_add = [{'email': email} for email in attendee_emails if email not in current_emails]
    
    if not new_attendees_to_add:
        return GoogleCalendarEvent(**event)
        
    updated_attendee_list = current_attendees + new_attendees_to_add
    patch_body = {'attendees': updated_attendee_list}
    
    try:
        updated_event = service.events().patch(calendarId=calendar_id, eventId=event_id, body=patch_body, sendNotifications=send_notifications).execute()
        return GoogleCalendarEvent(**updated_event)
    except HttpError as error:
        raise error
    except Exception as e:
        raise e

def create_calendar(
    credentials: Credentials, summary: str
) -> Optional[CalendarListEntry]:
    service = _get_calendar_service(credentials)
    if not service: return None
    calendar_body = {'summary': summary}
    try:
        created_calendar = service.calendars().insert(body=calendar_body).execute()
        return CalendarListEntry(**created_calendar)
    except HttpError as error:
        raise error
    except Exception as e:
        raise e

def check_attendee_status(
    credentials: Credentials, event_id: str, calendar_id: str = 'primary', attendee_emails: Optional[List[str]] = None
) -> Optional[Dict[str, str]]:
    service = _get_calendar_service(credentials)
    if not service: return None
    try:
        event = service.events().get(calendarId=calendar_id, eventId=event_id).execute()
    except HttpError as error:
        raise error

    attendees = event.get('attendees', [])
    if not attendees: return {}
    
    status_map: Dict[str, str] = {}
    target_emails_set = set(attendee_emails) if attendee_emails is not None else None
    
    for attendee in attendees:
        email = attendee.get('email')
        status = attendee.get('responseStatus')
        if not email or not status: continue
        if target_emails_set is not None:
            if email in target_emails_set: status_map[email] = status
        else:
            status_map[email] = status
            
    return status_map

def find_availability(
    credentials: Credentials, time_min: datetime, time_max: datetime, calendar_ids: List[str]
) -> Optional[Dict[str, Dict[str, Any]]]:
    service = _get_calendar_service(credentials)
    if not service: return None
    if not calendar_ids: return {}
    
    time_min_str = time_min.isoformat() + ('Z' if time_min.tzinfo is None else '')
    time_max_str = time_max.isoformat() + ('Z' if time_max.tzinfo is None else '')
    
    request_body = {"timeMin": time_min_str, "timeMax": time_max_str, "items": [{"id": cal_id} for cal_id in calendar_ids]}
    
    try:
        freebusy_result = service.freebusy().query(body=request_body).execute()
        processed_results: Dict[str, Dict[str, Any]] = {}
        calendars_data = freebusy_result.get('calendars', {})
        for cal_id, data in calendars_data.items():
            busy_intervals = []
            for interval in data.get('busy', []):
                try:
                    start_dt = parser.isoparse(interval.get('start'))
                    end_dt = parser.isoparse(interval.get('end'))
                    busy_intervals.append({'start': start_dt, 'end': end_dt})
                except (TypeError, ValueError) as parse_error:
                    logger.warning(f"Could not parse busy interval for {cal_id}: {interval}. Error: {parse_error}")
            processed_results[cal_id] = {'busy': busy_intervals, 'errors': data.get('errors', [])}
            
        return processed_results
    except HttpError as error:
        raise error
    except Exception as e:
        raise e

def _merge_intervals(intervals: List[Dict[str, datetime]]) -> List[Dict[str, datetime]]:
    if not intervals: return []
    sorted_intervals = sorted(intervals, key=lambda x: x['start'])
    merged = [sorted_intervals[0]]
    for current in sorted_intervals[1:]:
        last_merged = merged[-1]
        if current['start'] <= last_merged['end']:
            merged[-1]['end'] = max(last_merged['end'], current['end'])
        else:
            merged.append(current)
    return merged

def _find_first_available_slot(
    time_min: datetime, time_max: datetime, duration: timedelta, busy_intervals: List[Dict[str, datetime]],
    working_hours_start: Optional[time] = None, working_hours_end: Optional[time] = None,
) -> Optional[Tuple[datetime, datetime]]:
    try:
        time_min_utc = time_min.astimezone(timezone.utc) if time_min.tzinfo else time_min.replace(tzinfo=timezone.utc)
        time_max_utc = time_max.astimezone(timezone.utc) if time_max.tzinfo else time_max.replace(tzinfo=timezone.utc)
        now_utc = datetime.now(timezone.utc)
    except Exception as tz_err:
        logger.error(f"Error normalizing timezones to UTC: {tz_err}")
        return None
        
    effective_start = max(time_min_utc, now_utc)
    busy_intervals_utc = []
    for interval in busy_intervals:
        try:
            start_utc = interval['start'].astimezone(timezone.utc) if interval['start'].tzinfo else interval['start'].replace(tzinfo=timezone.utc)
            end_utc = interval['end'].astimezone(timezone.utc) if interval['end'].tzinfo else interval['end'].replace(tzinfo=timezone.utc)
            busy_intervals_utc.append({'start': start_utc, 'end': end_utc})
        except Exception as busy_tz_err:
             logger.warning(f"Could not normalize busy interval to UTC: {busy_tz_err}")
             
    busy_intervals_utc.sort(key=lambda x: x['start'])
    current_search_time = effective_start
    
    def is_within_working_hours(slot_start: datetime, slot_end: datetime) -> bool:
        if not working_hours_start or not working_hours_end: return True
        try:
             return (working_hours_start <= slot_start.time() and slot_end.time() <= working_hours_end and slot_start.date() == slot_end.date())
        except TypeError: return True
        
    while current_search_time < time_max_utc:
        potential_end_time = current_search_time + duration
        if potential_end_time > time_max_utc: break
        
        overlap_found = False
        for busy in busy_intervals_utc:
            if current_search_time < busy['end'] and potential_end_time > busy['start']:
                current_search_time = busy['end']
                overlap_found = True
                break
                
        if overlap_found: continue
        
        if is_within_working_hours(current_search_time, potential_end_time):
            return current_search_time, potential_end_time
        else:
            current_search_time += timedelta(minutes=15)
            
    return None

def find_mutual_availability_and_schedule(
    credentials: Credentials, attendee_calendar_ids: List[str], time_min: datetime, time_max: datetime,
    duration_minutes: int, event_details: EventCreateRequest, organizer_calendar_id: str = 'primary',
    working_hours_start: Optional[time] = None, working_hours_end: Optional[time] = None, send_notifications: bool = True
) -> Optional[GoogleCalendarEvent]:
    availability_data = find_availability(credentials, time_min, time_max, attendee_calendar_ids)
    if availability_data is None: return None
    
    all_busy_intervals: List[Dict[str, datetime]] = []
    for cal_id, data in availability_data.items():
        if data.get('errors'): logger.warning(f"Errors fetching availability for {cal_id}: {data['errors']}")
        all_busy_intervals.extend(data.get('busy', []))
        
    merged_busy = _merge_intervals(all_busy_intervals)
    duration = timedelta(minutes=duration_minutes)
    
    available_slot = _find_first_available_slot(time_min, time_max, duration, merged_busy, working_hours_start, working_hours_end)
    
    if not available_slot:
        logger.warning("No mutually available time slot found.")
        return None
        
    slot_start, slot_end = available_slot
    
    final_event_data = event_details.copy(deep=True)
    final_event_data.start = EventDateTime(date_time=slot_start)
    final_event_data.end = EventDateTime(date_time=slot_end)
    
    existing_attendees = {att.email for att in final_event_data.attendees} if final_event_data.attendees else set()
    for email in attendee_calendar_ids:
        if email == 'primary': continue
        if email not in existing_attendees:
            if final_event_data.attendees is None: final_event_data.attendees = []
            final_event_data.attendees.append(EventAttendee(email=email, responseStatus='needsAction'))
            existing_attendees.add(email)
    
    action_response = create_event(
        credentials=credentials, 
        event_data=final_event_data, 
        calendar_id=organizer_calendar_id, 
        user_info={}, 
        send_notifications=send_notifications
    )

    if action_response and action_response.event:
        return action_response.event
    else:
        logger.error("Failed to create the event after finding an available slot.")
        return None

def get_projected_recurring_events(
    credentials: Credentials, time_min: datetime, time_max: datetime,
    calendar_id: str = 'primary', event_query: Optional[str] = None
) -> List[ProjectedEventOccurrence]:
    return project_recurring_events(credentials, time_min, time_max, calendar_id, event_query)

def get_busyness_analysis(
    credentials: Credentials, time_min: datetime, time_max: datetime, calendar_id: str = 'primary'
) -> Optional[Dict[date, Dict[str, Any]]]:
    try:
        return analyze_busyness(credentials, time_min, time_max, calendar_id)
    except Exception as e:
        logger.error(f"Error during busyness analysis execution: {e}", exc_info=True)
        raise e

# Em src/calendar_actions.py, adicione esta nova função

# Em src/calendar_actions.py, SUBSTITUA a função delete_recurring_event por esta:

# Em src/calendar_actions.py, SUBSTITUA a função delete_recurring_event inteira por esta:

def delete_recurring_event(credentials: Credentials, event_id: str, calendar_id: str, delete_scope: str, settings: dict) -> ActionResponse:
    """
    Deleta um evento recorrente com base no escopo ('this_event', 'future_events' ou 'all_events').
    """
    service = _get_calendar_service(credentials)
    
    try:
        event_instance = service.events().get(calendarId=calendar_id, eventId=event_id).execute()
    except HttpError:
        raise HTTPException(status_code=404, detail="Evento a ser deletado não encontrado.")

    # --- CASO 1: Excluir apenas esta ocorrência ---
    if delete_scope == 'this_event':
        # Apagamos o evento individual pelo seu ID.
        service.events().delete(calendarId=calendar_id, eventId=event_id).execute()
        _handle_block_updates_on_delete(service, event_instance, settings)
        return ActionResponse(message="Apenas esta ocorrência do evento foi cancelada.")

    # --- CASO 2: Excluir esta e as futuras ocorrências (O BLOCO QUE FALTAVA) ---
    elif delete_scope == 'future_events':
        series_id = event_instance.get('extendedProperties', {}).get('private', {}).get('seriesId')
        if not series_id:
            raise HTTPException(status_code=400, detail="Este não é um evento de uma série válida.")
        
        # Lista todos os eventos da mesma série a partir da data do evento clicado
        instance_start_dt = parser.isoparse(event_instance['start']['dateTime'])
        
        future_events = service.events().list(
            calendarId=calendar_id,
            privateExtendedProperty=f"seriesId={series_id}",
            timeMin=instance_start_dt.isoformat()
        ).execute().get('items', [])
        
        for event_to_delete in future_events:
            service.events().delete(calendarId=calendar_id, eventId=event_to_delete['id']).execute()
            _handle_block_updates_on_delete(service, event_to_delete, settings)
            
        return ActionResponse(message=f"{len(future_events)} agendamento(s) (este e os futuros) foram excluídos.")

    # --- CASO 3: Excluir todas as ocorrências da série (passadas e futuras) ---
    elif delete_scope == 'all_events':
        series_id = event_instance.get('extendedProperties', {}).get('private', {}).get('seriesId')
        if not series_id:
            raise HTTPException(status_code=400, detail="Este não é um evento de uma série válida.")

        # Lista TODOS os eventos da mesma série, sem filtro de data
        all_series_events = service.events().list(
            calendarId=calendar_id,
            privateExtendedProperty=f"seriesId={series_id}"
        ).execute().get('items', [])
        
        for event_to_delete in all_series_events:
            service.events().delete(calendarId=calendar_id, eventId=event_to_delete['id']).execute()
            _handle_block_updates_on_delete(service, event_to_delete, settings)
        
        return ActionResponse(message=f"Todos os {len(all_series_events)} agendamento(s) da série foram excluídos.")
    
    else:
        raise HTTPException(status_code=400, detail="Escopo de exclusão inválido.")